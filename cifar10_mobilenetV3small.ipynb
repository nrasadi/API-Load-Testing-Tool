{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-mobilenetV3small.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1QxlPkFKYH41vuNKHbY1bp-8DR-iCC5nU",
      "authorship_tag": "ABX9TyMtPBmiB8VpiQqqoIXCG+W3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrasadi/API-Load-Testing-Tool/blob/master/cifar10_mobilenetV3small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILLoTQg4KDon",
        "outputId": "292c9a1f-b313-44f1-a98d-2136f3b9f76c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb  3 18:29:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIR0NKY79cDR",
        "outputId": "86cba36d-7d7d-45fa-e7b9-2ea345f00817"
      },
      "source": [
        "!git clone https://github.com/Scalable-DNN/pretrained-models.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pretrained-models'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J2tmSEgH_EV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dca3240-93f4-472c-9249-b7478c0990b9"
      },
      "source": [
        "!pip install larq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting larq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/60/5fb36a5a4a272e5214963c891dce9eb6bf2222a0fb90178b9e8dd25d4e37/larq-0.10.3-py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20kB 26.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 40kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 51kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 61kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from larq) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from larq) (0.8)\n",
            "Collecting terminaltables>=3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Requirement already satisfied: importlib-metadata<4.0,>=2.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from larq) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4.0,>=2.0; python_version < \"3.8\"->larq) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4.0,>=2.0; python_version < \"3.8\"->larq) (3.4.0)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=42affdeb4873ca936c8b9ccb9487e21cc8e2f7d9d7654b3f51cc238f4adc65a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, larq\n",
            "Successfully installed larq-0.10.3 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxSet09L-OBE"
      },
      "source": [
        "# %%bash\n",
        "# cd pretrained-models\n",
        "# git pull https://github.com/Scalable-DNN/pretrained-models.git"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gOe_ITO-svj"
      },
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications as kapp, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import larq as lq\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVD4dXo5_Snv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115061b3-1324-46db-ca74-5a834fa43f3c"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnF-kHUIAfLH"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwzmhlqDA_Np",
        "outputId": "ebab2cc8-d7a6-4b80-b932-78040c8a39c9"
      },
      "source": [
        "print(\"X_train.shape: {}\\tY_train.shape: {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"X_val.shape:   {}\\tY_val.shape:   {}\".format(x_val.shape, y_val.shape))\n",
        "print(\"X_test.shape:  {}\\tY_test.shape:  {}\".format(x_test.shape, y_test.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape: (40000, 32, 32, 3)\tY_train.shape: (40000, 1)\n",
            "X_val.shape:   (10000, 32, 32, 3)\tY_val.shape:   (10000, 1)\n",
            "X_test.shape:  (10000, 32, 32, 3)\tY_test.shape:  (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xAVoOVl_9sH"
      },
      "source": [
        "to_categorical = keras.utils.to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_quB16yBqq0"
      },
      "source": [
        "DataGen = keras.preprocessing.image.ImageDataGenerator\n",
        "\n",
        "transformations = {\n",
        "    'rotation_range': 5,\n",
        "    # 'featurewise_std_normalization': True,\n",
        "    # 'featurewise_center': True,\n",
        "    'zoom_range': .2,\n",
        "    'horizontal_flip': True,\n",
        "    # 'preprocessing_function': kapp.mobilenet_v3.preprocess_input\n",
        "}\n",
        "\n",
        "train_generator = DataGen(**transformations)\n",
        "val_generator   = DataGen(**transformations)\n",
        "test_generator  = DataGen(**transformations)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4f2WCsdGp-j"
      },
      "source": [
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdDSupPBHGSG",
        "outputId": "05853f35-c500-45e1-c4fc-165b2317fba1"
      },
      "source": [
        "core_model = kapp.MobileNetV3Small(x_train.shape[1:], weights='imagenet', include_top=False, classes=y_train.shape[-1])\n",
        "core_model.trainable = True\n",
        "\n",
        "inputs = keras.layers.Input(shape=x_train.shape[1:])\n",
        "\n",
        "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2\n",
        "# Scale inputs to [-1, +1]\n",
        "x = norm_layer(inputs)\n",
        "norm_layer.set_weights([mean, var])\n",
        "\n",
        "x = core_model(x, training=True)\n",
        "x = keras.layers.GlobalAveragePooling2D(name='global_average_pooling')(x)\n",
        "x = keras.layers.Reshape((1, 1, -1))(x)\n",
        "x = keras.layers.Dropout(.2, name='dropout', )(x)\n",
        "x = keras.layers.Conv2D(filters = y_train.shape[-1], kernel_size=1, name='logits')(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "outputs = keras.layers.Activation('softmax', name='predictions')(x)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# model.summary()\n",
        "# lq.models.summary(model)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP4gmISRMrxA"
      },
      "source": [
        "batch_size = 8192\n",
        "epochs = 1000\n",
        "lr = 1e-2\n",
        "\n",
        "optimzer = keras.optimizers.Adam(learning_rate=lr)\n",
        "callbacks = [\n",
        "            keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=.1, patience=5),\n",
        "            keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/0Works/cooparetive/mobilenetV3', monitor='val_accuracy', save_best_only=True)\n",
        "]\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mvG0JJBSXAb"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgFoDWLgOKM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f14185d-7d11-4206-d642-f7ca44d732c0"
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(core_model.layers))\n",
        "\n",
        "core_model.trainable = True\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in core_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimzer, loss='categorical_crossentropy', metrics=['accuracy'], )"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-t4zXLJWcN2"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "hIshAolzOfR3",
        "outputId": "0b5b46cd-dfae-4a74-ccf7-a7aaee5633cc"
      },
      "source": [
        "model.fit(\n",
        "    train_generator.flow(x_train, y_train, batch_size),\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    validation_data=val_generator.flow(x_val, y_val, batch_size),\n",
        "    validation_steps=x_val.shape[0] // batch_size,\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-d6cdf1f9051d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDCxE-SpSdkd"
      },
      "source": [
        "## Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mvJkhT8UXKU",
        "outputId": "90d07ab4-5ca2-47d6-d579-d135b37df16d"
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(core_model.layers))\n",
        "\n",
        "core_model.trainable = True\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in core_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HgQT3BKUlEF"
      },
      "source": [
        "epochs = 500\n",
        "model.compile(optimizer=optimzer, loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'], )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjjuU9FbVBID"
      },
      "source": [
        "model.fit(\n",
        "    train_generator.flow(x_train, y_train, batch_size),\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    validation_data=val_generator.flow(x_val, y_val, batch_size),\n",
        "    validation_steps=x_val.shape[0] // batch_size,\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROJUK6K2VLj7",
        "outputId": "96b9e369-ba72-48c1-f0af-f7a2c58706d4"
      },
      "source": [
        "%%bash\n",
        "cd pretrained-models/\n",
        "mkdir mobilenetV3small\n",
        "cp \"/content/drive/MyDrive/Colab\\ Notebooks/cocifar10-mobilenetV3small.ipynb\" \"/content/pretrained-models/mobilenetV3small\""
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘mobilenetV3small’: File exists\n",
            "cp: cannot stat '/content/drive/MyDrive/Colab\\ Notebooks/cocifar10-mobilenetV3small.ipynb': No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsEUhq1tImbb"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/cifar10-mobilenetV3small.ipynb\" \"/content/pretrained-models/mobilenetV3small\""
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkT8ihHTI0jy",
        "outputId": "0e67750c-0234-4134-857c-7ba5911e6c10"
      },
      "source": [
        "%%bash\n",
        "cd \"/content/pretrained-models/\"\n",
        "# git add -a\n",
        "# git commit -m \"Add mobilenetV3small notebook\"\n",
        "# git status\n",
        "# git push nrasadi@github.com master\n",
        "git config --global "
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\tmobilenetV3small/\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@65611df569ed.(none)')\n",
            "error: src refspec master does not match any.\n",
            "error: failed to push some refs to 'nrasadi@github.com'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF5GtFiLHFdw",
        "outputId": "281fe227-4319-4a59-83b7-383770cc02f7"
      },
      "source": [
        "%%bash \n",
        "echo $PWD"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVL4tT_2GliR",
        "outputId": "08c0512c-4d5e-47e6-db36-766b25ea3b97"
      },
      "source": [
        "!ls drive/MyDrive/Colab\\ Notebooks"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 7segment-02.ipynb\n",
            " 7segment.ipynb\n",
            "'BBox Proposal Based on Edge Detection.ipynb'\n",
            " charnet.ipynb\n",
            " CIFAR10-BNN.ipynb\n",
            "'cifar10-mobilenetV3small (1).ipynb'\n",
            " cifar10-mobilenetV3small.ipynb\n",
            "'Copy of 2.5 Audio Recognition using Siamese Network.ipynb'\n",
            "'Copy of 7segment.ipynb'\n",
            "'Copy of cifar10-mobilenetV3small.ipynb'\n",
            "'Copy of Course 1 - Part 4 - Lesson 2 - Notebook.ipynb'\n",
            "'Copy of demo.ipynb'\n",
            "'Copy of Exercise 1 - House Prices - Question.ipynb'\n",
            "'Copy of Exercise2-Question.ipynb'\n",
            "'Copy of interactive_eager_few_shot_od_training_colab.ipynb'\n",
            "'Copy of Mask-Navidreza (1).ipynb'\n",
            "'Copy of Mask-Navidreza.ipynb'\n",
            "'Copy of Mask-Navidreza-split.ipynb'\n",
            "'Copy of Mask R-CNN Demo'\n",
            "'Copy of Object detection'\n",
            "'Copy of object_detection_tutorial.ipynb'\n",
            "'Copy of Roboflow-TensorFlow2-Object-Detection.ipynb'\n",
            "'Data Augmentation.ipynb'\n",
            "'download kitti.ipynb'\n",
            " EfficientDNN-HW1.ipynb\n",
            "'EfficientNet Keras Transfer Learning.ipynb'\n",
            "'evaluate imagenet validation set.ipynb'\n",
            " generate_glucometers.ipynb\n",
            "'GettingFamilliarWith Pascal VOC 2012.ipynb'\n",
            " HarmonySearch-13Tir98.ipynb\n",
            " harmony_search-27ord98.ipynb\n",
            " loader_io_payload-Copy.txt\n",
            " loader_io_payload.txt\n",
            " Mask-Navidreza-split.ipynb\n",
            "'Mask R-CNN Demo - AllinOne'\n",
            "'Mask R-CNN Demo - Corrected'\n",
            "'Mobile Mask.ipynb'\n",
            " model4glucometer-effnet.ipynb\n",
            " model4glucometer-mobnet.ipynb\n",
            " new_users.ipynb\n",
            " split_model_example.ipynb\n",
            "'Stress Test-26Farvardin.ipynb'\n",
            " strsTest-24Ordi.ipynb\n",
            " telegram_bot.ipynb\n",
            " train_single_digit.ipynb\n",
            " Untitled0.ipynb\n",
            " Untitled10.ipynb\n",
            " Untitled11.ipynb\n",
            " Untitled12.ipynb\n",
            " Untitled13.ipynb\n",
            " Untitled14.ipynb\n",
            " Untitled15.ipynb\n",
            " Untitled16.ipynb\n",
            " Untitled17.ipynb\n",
            " Untitled18.ipynb\n",
            " Untitled19.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n",
            " Untitled3.ipynb\n",
            " Untitled4.ipynb\n",
            " Untitled5.ipynb\n",
            " Untitled6.ipynb\n",
            " Untitled7.ipynb\n",
            " Untitled8.ipynb\n",
            " Untitled9.ipynb\n",
            " user_data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}